<!DOCTYPE html>
<html lang="it">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Capitolo 3.5 â€“ Processi, Scheduling e Memoria</title>
    <link rel="stylesheet" href="../../../style/style.css" />
  </head>
  <body>
    <div class="viewer-content">
      <header>
        <h1>ğŸ’» Capitolo 3.5 â€“ Processi, Scheduling e Memoria</h1>
      </header>

      <main>
        <section>
          <h2>ğŸ“Œ 1. Programma vs Processo</h2>
          <ul>
            <li>
              <strong>Programma</strong> â†’ insieme di istruzioni (statico, come
              una ricetta).
            </li>
            <li>
              <strong>Processo</strong> â†’ programma in esecuzione (dinamico,
              come il cuoco che prepara).
            </li>
          </ul>

          <p>
            ğŸ‘‰ Il sistema operativo gestisce <strong>processi</strong>, non
            programmi.
          </p>
          <p>
            Ogni processo Ã¨ rappresentato dal
            <strong>PCB (Process Control Block)</strong>, che contiene:
          </p>
          <ul>
            <li>PID (identificatore)</li>
            <li>Memoria assegnata</li>
            <li>Registri e program counter</li>
            <li>File aperti</li>
            <li>PrioritÃ , sicurezza, ecc.</li>
          </ul>

          <p>
            ğŸ”¹ Il <strong>kernel</strong> controlla i processi (puÃ² fermarli,
            riattivarli, sospenderli).
          </p>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 2. Monotasking</h2>
          <ul>
            <li>
              Nei primi sistemi â†’ la CPU eseguiva una sola cosa alla volta.
            </li>
            <li>
              Problema â†’ CPU velocissima, ma spesso inattiva in attesa di I/O.
            </li>
          </ul>

          <p>ğŸ’¾ <strong>Esempi</strong> â†’ MS-DOS, Apple II, Commodore 64.</p>
          <p>
            ğŸ’¡ <strong>Batch processing</strong> â†’ lavori eseguiti a lotti, uno
            dopo lâ€™altro.
          </p>
          <p>
            ğŸ’¡ <strong>Spooling</strong> â†’ buffer per gestire dispositivi lenti
            (es. stampante).
          </p>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 3. Interruzioni</h2>
          <ul>
            <li>
              <strong>Polling</strong> â†’ la CPU chiede sempre ai dispositivi â†’
              lento.
            </li>
            <li>
              <strong>Interrupt</strong> â†’ i dispositivi avvisano la CPU â†’
              efficiente.
            </li>
          </ul>
          <p>â¡ï¸ Le interruzioni rendono possibile multitasking ed eventi.</p>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 4. Multiprogrammazione (Multitasking cooperativo)</h2>
          <ul>
            <li>PiÃ¹ programmi in memoria â†’ la CPU passa da uno allâ€™altro.</li>
            <li>Non Ã¨ vero multitasking, ma lâ€™utente lo percepisce.</li>
          </ul>

          <p>
            Richiede: <strong>scheduler</strong>, cambio di contesto, gestione
            memoria.
          </p>

          <h3>Stati di un processo</h3>
          <ul>
            <li><strong>New</strong> â†’ creato</li>
            <li><strong>Ready</strong> â†’ pronto, attende la CPU</li>
            <li><strong>Execute</strong> â†’ in esecuzione</li>
            <li><strong>Wait/Blocked</strong> â†’ in attesa di I/O</li>
            <li><strong>Terminate</strong> â†’ concluso</li>
          </ul>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 5. Multitasking preemptive</h2>
          <p>
            Il kernel puÃ² interrompere un processo. Ogni processo ha un
            <strong>quantum</strong> (tempo massimo).
          </p>

          <h3>âœ… Vantaggi</h3>
          <ul>
            <li>CPU condivisa tra piÃ¹ utenti</li>
            <li>Meno blocchi</li>
            <li>Esperienza fluida</li>
          </ul>

          <p>
            ğŸ”¹ Tutti i moderni OS (Windows, Linux, macOS, Android, iOS) usano
            questo metodo.
          </p>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 6. Algoritmi di Scheduling</h2>
          <ul>
            <li><strong>FCFS</strong> â†’ First Come, First Served</li>
            <li><strong>SJF</strong> â†’ Shortest Job First</li>
            <li><strong>Round Robin</strong> â†’ ogni processo ha un quantum</li>
            <li>
              <strong>MLQ</strong> â†’ code multiple con prioritÃ  (rischio
              starvation)
            </li>
            <li><strong>SRT</strong> â†’ versione preemptive di SJF</li>
            <li><strong>MLF</strong> â†’ prioritÃ  dinamiche + quantum diversi</li>
          </ul>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ 7. Thread</h2>
          <p>
            I processi sono â€œpesantiâ€, mentre i <strong>thread</strong> sono piÃ¹
            leggeri e condividono risorse del processo.
          </p>

          <h3>âœ… Vantaggi</h3>
          <p>Meno overhead, piÃ¹ velocitÃ , parallelismo.</p>

          <h3>Esempio</h3>
          <p>
            Processo <strong>browser</strong> â†’ thread per scaricare pagina,
            immagini, aggiornare schermo.
          </p>

          <h3>Relazioni</h3>
          <ul>
            <li><strong>1:1</strong> â†’ un processo, un thread (MS-DOS)</li>
            <li>
              <strong>P:1</strong> â†’ piÃ¹ processi, un thread ciascuno (vecchio
              UNIX)
            </li>
            <li>
              <strong>1:T</strong> â†’ un processo, tanti thread (alcune app Java)
            </li>
            <li>
              <strong>P:T</strong> â†’ molti processi, ognuno con piÃ¹ thread
              (Windows, Linux, macOS moderni)
            </li>
          </ul>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ Riassunto Capitolo 3.5 â€“ La Memoria</h2>

          <h3>ğŸ— Gerarchia</h3>
          <ul>
            <li>Piccole â†’ veloci e costose</li>
            <li>Grandi â†’ lente ed economiche</li>
          </ul>
          <p>â¡ï¸ Uso di piÃ¹ livelli insieme.</p>

          <h3>3.5.1 Cache</h3>
          <ul>
            <li>CPU piÃ¹ veloce della RAM â†’ serve cache.</li>
            <li><strong>Cache hit</strong> âœ… â†’ dato trovato.</li>
            <li><strong>Cache miss</strong> âŒ â†’ CPU va in RAM.</li>
          </ul>

          <pre><code>Te = Tc Ã— h + (Tc + Tr) Ã— (1 âˆ’ h)</code></pre>
          <p>
            Tc = tempo cache<br />
            Tr = tempo RAM<br />
            h = hit ratio
          </p>

          <h4>Tipi di cache</h4>
          <ul>
            <li>Associativa â†’ veloce ma costosa</li>
            <li>Mappa diretta â†’ piÃ¹ semplice</li>
          </ul>

          <p><strong>Scrittura:</strong></p>
          <ul>
            <li>Write-through (sicura, lenta)</li>
            <li>Write-back (veloce, rischiosa)</li>
          </ul>

          <p>â¡ï¸ Cache anche per disco, browser, TLB.</p>
        </section>

        <hr />

        <section>
          <h3>3.5.2 Memoria Centrale</h3>
          <p>Gestita da <strong>MMU</strong>. Metodi:</p>

          <h4>Paginazione</h4>
          <ul>
            <li>Memoria divisa in pagine e frame.</li>
            <li>Page table â†’ traduzione logico-fisico.</li>
            <li>âœ… Niente frammentazione esterna.</li>
            <li>âš ï¸ Overhead per PMMU.</li>
          </ul>

          <h4>Segmentazione</h4>
          <ul>
            <li>Memoria in segmenti (codice, dati, stack).</li>
            <li>PiÃ¹ flessibile ma piÃ¹ complessa.</li>
          </ul>

          <h4>Segmentazione paginata</h4>
          <p>Mix dei due sistemi.</p>
        </section>

        <hr />

        <section>
          <h3>3.5.3 Memoria Virtuale</h3>
          <ul>
            <li>Parte del disco usata come RAM.</li>
            <li>Tecnica â†’ <strong>demand paging</strong>.</li>
            <li><strong>Page fault</strong> â†’ caricamento da disco.</li>
            <li><strong>Thrashing</strong> â†’ troppi swap.</li>
          </ul>

          <p>ğŸ’¡ Soluzioni: TLB, resident set, partizioni/file di swap.</p>
        </section>

        <hr />

        <section>
          <h3>3.5.4 Riassunto</h3>
          <ul>
            <li>Cache â†’ veloce, piccola</li>
            <li>RAM â†’ media</li>
            <li>Disco (memoria virtuale) â†’ grande, lenta</li>
          </ul>

          <p><strong>Gestione multitasking:</strong></p>
          <ul>
            <li>Paginazione â†’ blocchi fissi</li>
            <li>Segmentazione â†’ blocchi variabili</li>
            <li>Segmentazione paginata â†’ combinazione</li>
          </ul>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ Gestione logica dei volumi e RAID</h2>

          <h3>ğŸ”¹ Volumi logici</h3>
          <p>
            Partizioni rigide â†’ difficile cambiarle.<br />
            Con <strong>LVM/JBOD</strong> â†’ piÃ¹ partizioni unite in uno spazio
            unico.
          </p>
          <p>âœ… Espandibile, gestibile come un solo disco.</p>

          <h3>ğŸ”¹ RAID</h3>
          <p>PiÃ¹ dischi come uno solo. PuÃ² essere software o hardware.</p>

          <h4>Tipi base</h4>
          <ul>
            <li>
              <strong>RAID-0 (Striping)</strong> â†’ veloce, zero sicurezza.
            </li>
            <li>
              <strong>RAID-1 (Mirroring)</strong> â†’ dati duplicati, affidabile.
            </li>
            <li>
              <strong>RAID-5</strong> â†’ striping + paritÃ  â†’ compromesso tra
              velocitÃ  e sicurezza.
            </li>
          </ul>
        </section>

        <hr />

        <section>
          <h2>ğŸ“Œ Capitolo 1.1.1 â€“ Processi: competizione e cooperazione</h2>
          <p>
            <strong>Processo</strong> = programma in esecuzione. Info nel PCB:
            memoria, file, prioritÃ , registri.
          </p>

          <h3>ğŸ”¹ Processi indipendenti vs interagenti</h3>
          <ul>
            <li><strong>Indipendenti</strong> â†’ risultato deterministico.</li>
            <li><strong>Interagenti</strong> â†’ influenzano altri processi.</li>
          </ul>

          <p>Due forme:</p>
          <ul>
            <li><strong>Competizione</strong> â†’ risorse contese</li>
            <li><strong>Cooperazione</strong> â†’ collaborazione tra processi</li>
          </ul>

          <h3>ğŸ”¹ Concorrenza vs Parallelismo</h3>
          <ul>
            <li>
              <strong>Concorrenza</strong> â†’ processi si alternano sulla stessa
              CPU.
            </li>
            <li>
              <strong>Parallelismo</strong> â†’ processi su piÃ¹ core
              contemporaneamente.
            </li>
          </ul>

          <h3>ğŸ”¹ Tassonomia di Flynn</h3>
          <ul>
            <li><strong>SISD</strong> â†’ 1 istruzione, 1 dato (Von Neumann)</li>
            <li><strong>SIMD</strong> â†’ 1 istruzione, piÃ¹ dati (MMX, PS2)</li>
            <li>
              <strong>MIMD</strong> â†’ piÃ¹ istruzioni, piÃ¹ dati (multicore
              moderni)
            </li>
          </ul>
        </section>
      </main>
    </div>
  </body>
</html>
